---
title: 任务二 使用神经网络预测点在圆形内还是圆形外 实践引导补充
created: '2025-12-01T02:39:48.612Z'
modified: '2025-12-03T05:02:06.791Z'
---

# 任务二 使用神经网络预测点在圆形内还是圆形外 实践引导补充

如果你在看完learn_it中的实践引导还是觉得不好上手，不妨看看这个吧~

注1：如果你需要一个通用、规范、全面的代码参考，请见reference\neuralNetwork_test\network_test.py。
本教程的代码为了易懂丧失了拓展性，也缺乏很多功能，仅作为入门学习的参考。

注2：你不必熟练numpy，有不会的用法问ai就行
如果你写的和我的差距较大，不要慌张。你可以选择先完成你的再看教程，也可以选择继续看。不同不意味着错误，可能是思路不同或实现顺序不同。

## 一.我们怎么集成模型的功能？python中类的使用

训练一个模型需要定义很多东西，前向、反向传播，RELU，交叉熵等等各种计算需要的函数。单单是一个多层感知机就需要不少代码，而在人工智能的论文中，不乏多种模型嵌套的情况。不梳理好代码层级，随着结构的增加，代码库便会臃肿到人类几乎不可读的可怕状态。为了解决这种困境，我们通常用类（class）来封装和模型有关的各种功能。在开始之前，推荐你先看看这篇文章：

[点这里看python类的简单教程](https://zhuanlan.zhihu.com/p/30024792)

接下来，我们将一步一步动手搭建一个 MLPClassifier 类（它的意思是多层感知机分类器）来封装一个迷你的多层感知机模型。

### 1. 基本框架与初始化

我们搭建一个空框架：
```python
class MLPClassifier:
  def __init__(self,...):
    """
    这里需要完成模型的初始化,包括对变量和函数的声明
    """

  def some_function(self,some_parameter=some_initial_value,...)
    """
    接下来，需要完成对已经声明的各种函数的定义
    """
    return something
```
我们需要列出需要的部件，一步步丰满这个框架。

#### 回顾：我们需要什么？
回顾我们需要实现的多层感知机训练流程：
我们需要输入若干点的数据，这些数据的格式是：若干行，3列的csv文件。3列分别是x,y,label，其中label仅当其在圆形区域内时为1，其余时刻为0。
也就是说，我们要把数据格式送进这个类。我们可以扩充__init__ (即初始化函数)如下：
```python
def __init__(self,datasets):
  self.datasets=datasets

```
<details><summary><h3>self是什么意思呢？</h3>（点击展开~如果你通过看前面的知乎教程已经会了这块，请跳至1.我们要实现数据到独热格式的转换部分）</summary>
我们定义的这个类不仅封装了函数功能，更重要的是，它如果赋给一个实例，那么那个实例应该担起记录变量信息（如数据和模型参数与权重）的责任。比如：
```python
def MLPClassifier:
  ...#定义这个类的过程省略

Model1 = MLPClassifier(datasets=Data1,...)
Model2 = MLPClassifier(datasets=Data2,...)
```
以上的代码中，我们创建了Model1和Model2两个**对象**。这两个对象在分别执行类的函数时，应该分别调用他们本身的数据。比如，如果我执行以下函数：

```python
Weight1 = Model1.weight()
```
那么，按理来说，我们不应再向weight中传入本身已经在Model1记录过的信息。那样就太麻烦了，更违背了我们用类封装模型的初衷。
比如以下的类设计就是不合格的：
```python
def MLPClassifier:
  ...#定义这个类的过程省略

classifier = MLPClassifier(...)
Weight1 = classifier.weight(model=Model1)
Weight2 = classifier.weight(model=Model2)
```
这时候，MLPClassifier的定位与其是类，不如说更像一个**库**，而classifier对象的创建更像是简单给MLPClassifier这个“库”改了个名字，完全没有承载数据信息。
这里如果不是那么明白区别在哪，可以对照前面推荐的代码多对比下，实在不懂往下看也没事。
说了那么多，终于要引入self关键词的概念————
self，便是用来将局部变量转化为**实例属性**的关键词。
##### self有如下属性：任何定义在类中的函数，第一个变量必然是self（代表示例本身）。
比如前面的定义中，
```python
def __init__(self,datasets):
  ...
```
只有引入实例本身，才能干预到实例的定义和引用。
而下一句，
```python
  self.datasets=datasets
```
便是将局部变量datasets赋给实例属性的语句。注意到，只有在初始化时才会运行类中的_init__函数，而这就是将局部变量赋给实例属性的唯一机会。如果错过了这次机会，那么我们以后如果再调用相关实例属性时，就要每次都传参，无比麻烦。比如这个不恰当的初始化：
```python
def __init__(self,datasets):
  pass

def process_data(self,datasets):
    sth = do_something(datasets)
  return sth
```
和正确的对比：
```python
def __init__(self,datasets):
  self.datasets=datasets

def process_data(self):
    sth = do_something(self.datasets)
  return sth
```
注意到，第一个的函数调用的是局部变量，每次调用都要传参。而第二个将datasets固定在了self实例中，即使函数周期结束也存在。不仅如此，第二个的函数只用传递self变量（注：也可视情况传递其他外部变量），当self蕴含的属性较多时，这样会简单非常多。
所以，所有的类属性都要在__init__中使用self关键词完成一次声明~

#### 如果函数不需要固定处理类中的属性，而是随程序进程灵活调用，那么可以不必利用self中的参数运算。例如：
```python
def __init__(self,datasets):
  pass

def process_data(self,datasets):
    sth = do_something(datasets)
  return sth

def add(self,x,y):
  return x + y

```
这里的add函数没有使用实例属性运算，单纯作为库中的函数工具存在。
</details>

我们可以利用流程图来更清晰地找到我们所需要用的模块，从而辅助我们的代码构建。
### 1.2.实现数据到独热格式的转换
即：我们把数据拆成坐标（前两列）和标签（第三列）两部分，坐标不变，将标签扩充为两列，分别代表其是否在圈内和是否在圈外。这样，我们便可以用softmax+CE（如果看到这都不知道这俩是啥，罚回去重读（））的形式，方便拓展到其他情境。注意，这个函数
那么，我们要定义函数,或者直接在init函数中处理，满足以上要求。

<details><summary>这里是一种实现方式</summary>

```python
import numpy as np
import pandas as pd


class MLPClassifier:
  def __init__(self,datasets):
    self.datasets = datasets
    self.X = get_coordinates()
    self.y = self.one_hot()

  def get_coordinates(self):
      coordinates = self.datasets[['x','y']].values
      return coordinates

  def one_hot(self):
      labels_onehot = pd.get_dummies(self.datasets['label'])
      return labels_onehot
```

</details>

<details><summary>这里是另一种实现方式</summary>

```python
import numpy as np
import pandas as pd


class MLPClassifier:
  def __init__(self,datasets):
    self.datasets = datasets
    self.X = self.datasets[['x','y']].values
    self.y = pd.get_dummies(self.datasets['label']).values
```

</details>

不用函数的第二种看起来简洁多了。以下以第二种为模板继续。第一种仅为了便于学习函数使用作为参考。




###  1.3.进一步完成初始化
我们的类要有一些特定的参数和功能。
从参数的角度，我们需要定义一些（在这里是3个）W矩阵（input_size\*output_size）和b向量(1\*output_size)。这部分内容详见learn\_it中的实践引导。
从功能的角度，我们需要定义初始化函数，使用到的各种激活函数以及损失的计算方式。最后，还要定义前向和反向传递的方式。

除此之外，为了方便地存储loss，我们可以开一个空数组，每过一个轮次就记录。
我们现在只声明，不定义，可以在不清楚的方式使用“...”代替，先潦草地搭好这个类的框架：

<details><summary>这里是一种实现方式</summary>

```python
import numpy as np
import pandas as pd


class MLPClassifier:
  def __init__(self,datasets):
    self.datasets = datasets
    self.X = self.datasets[['x','y']].values
    self.y = pd.get_dummies(self.datasets['label']).values
    self.W1 = (一些初始化方式...一会我们会把这个填充)
    self.b1 = （依旧是一些初始化方式）
    self.W2 = (一些初始化方式...一会我们会把这个填充)
    self.b2 = （依旧是一些初始化方式）
    self.W3 = (一些初始化方式...一会我们会把这个填充)
    self.b3 = （依旧是一些初始化方式）
    self.loss = []

  def softmax(self,...):
    ...

  def relu(self,...):
    ...

  def CE(self,...):
    ...

  def forward(self,...):
    ...

  def backward(self,...):
    ...

  def compute_loss(self,...):
    ...

```

</details>


接下来，我们要初始化矩阵权重。对于W，我们采用He初始化（也叫Kaiming初始化。[何恺明是谁？](https://zhuanlan.zhihu.com/p/1967687156727281013)）对于b，我们置零。
这个初始化的函数为:
std = np.sqrt(2.0 / input_size)
self.W = np.random.randn(input_size, output_size) * std
self.b = np.zeros((1, output_size))
即让W中的元素服从N（0，2 / input_size)的正态分布。

[看看He初始化的原理，如果你有兴趣的话](https://zhuanlan.zhihu.com/p/636235528)

<details><summary>下面是我们更新之后的全部代码</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,datasets):
        self.datasets = datasets
        self.X = self.datasets[['x','y']].values
        self.y = pd.get_dummies(self.datasets['label']).values
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []


     def softmax(self):
        ...

    def relu(self, M):
        ...
    
    def CE(self,M_pred,M_true):
        ...

    def forward(self,...):
        ...

    def backward(self,...):
        ...

    def compute_loss(self,...):
        ...

```

</details>

### 2.逐步定义softmax,relu和CE函数

这步比较简单，照着定义抄就行，借助ai做完对答案，或是看答案再复现都可以

注：定义softmax时别忘了运算前将每个量都减去这个向量中的最大值，不然会爆精度。
另外，注意 log y 和 log（1-y）都不能爆inf，所以要用np.clip稍加限制y的取值。
softmax是最后用logits计算概率时用的，所以要按列计算。

为了储存中间信息，我们多了一些初始化定义。你可以有其他写法。

以后我们还会一边扩建代码一边补充其他初始化定义。
<details><summary>这里是一种实现方式</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,datasets):
        self.datasets = datasets
        self.X = self.datasets[['x','y']].values
        self.y = pd.get_dummies(self.datasets['label']).values
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []
        self.H1 = None
        self.H2 = None
        self.logits = None


     def softmax(self):
        _ = np.exp(self.logits - np.max(self.logits, axis=1, keepdims=True))
        softmax_logits = _ / np.sum(_, axis=1, keepdims=True)
        return softmax_logits

    def relu(self, M):
        return np.maximum(0, M)
    
    def CE(self,M_pred,M_true):
        epsilon = 1e-10
        M_pred = np.clip(M_pred, epsilon, 1. - epsilon)
        M_CE = -M_true*np.log(M_pred)
        return M_CE

    def forward(self,...):
        ...

    def backward(self,...):
        ...

    def compute_loss(self,...):
        ...
```

</details>

### 3.定义前向传递（forward）和计算损失（compute_loss）函数

前向传递函数：我们要做的，就是计算X@W+b（这里形状不一样还能相加是由于numpy的[广播机制](https://zhuanlan.zhihu.com/p/683271041)）。
我们使用CE
损失函数：仅仅将交叉熵取均值即可。
(注意到：对于独热编码，交叉熵损失的计算就相当于-log(softmax(y_pred_true)),其中y_pred_true是预测正确那行的logit值）。）细节与计算方法详见learn_it任务二实践引导。
<details><summary>这里是一种实现方式</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,datasets):
        self.datasets = datasets
        self.X = self.datasets[['x','y']].values
        self.y = pd.get_dummies(self.datasets['label']).values
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []
        self.H1 = None
        self.H2 = None
        self.logits = None


     def softmax(self):
        _ = np.exp(self.logits - np.max(self.logits, axis=1, keepdims=True))
        softmax_logits = _ / np.sum(_, axis=1, keepdims=True)
        return softmax_logits

    def relu(self, M):
        return np.maximum(0, M)
    
    def CE(self,M_pred,M_true):
        epsilon = 1e-10
        M_pred = np.clip(M_pred, epsilon, 1. - epsilon)
        M_CE = -M_true*np.log(M_pred)
        return M_CE

    def compute_loss(self):
        return np.mean(np.sum(self.CE(self.softmax(),self.y),axis=1))

    def forward(self,...):
        self.H1 = self.relu(self.X @self.W1 + self.b1)
        self.H2 = self.relu(self.H1 @self.W2 + self.b2)
        self.logits = self.H2 @self.W3 + self.b3
        self.loss.append(self.compute_loss())

    def backward(self,...):
        ...


        
```

</details>


### 4.与反向传播（backward）相关的定义

这时，我们需要将后面的误差传播到前面。

具体的公式依旧详见learn_it.

我们在这里先不处理batch相关的内容，留到后面再做代码上的微调。

与此同时，我们补充定义了第一个超参数学习率Learning_rate，以便于反向传播的更新。

<details><summary>$$\frac{\partial L}{\partial logits}的公式是咋推的？（拓展阅读）$$</summary>

在learn_it中，我们给出了对最后一层线性输出 $z$ 的导数为
  
  $$\frac{\partial L}{\partial z} = \hat{y} - y$$ 

的结论。下面我们将尝试证明它，你可以先自己试试。

我们展开写$L$与$z$的关系式:
  
其中 $\hat{y} = \text{softmax}(z)$ 是预测概率分布，$y$ 是真实标签（one-hot编码）。

## 1. 定义符号和函数

设：
- $z = [z_1, z_2, \dots, z_C]^T$ 是线性层的输出（logits），$C$ 是类别数
- $\hat{y} = \text{softmax}(z) = [\hat{y}_1, \hat{y}_2, \dots, \hat{y}_C]^T$ 是预测概率分布
- $y = [y_1, y_2, \dots, y_C]^T$ 是真实标签的 one-hot 编码（只有一个元素为1，其余为0）
- 交叉熵损失：$L = -\sum_{i=1}^C y_i \log(\hat{y}_i)$

## 2. Softmax 函数的导数

首先，我们需要知道 softmax 函数对输入 $z$ 的偏导数。

对于 softmax 函数：
$$\hat{y}_i = \frac{e^{z_i}}{\sum_{j=1}^C e^{z_j}}$$

我们需要计算 $\frac{\partial \hat{y}_k}{\partial z_i}$，分两种情况：

**情况1：当 $k = i$ 时**
$$\frac{\partial \hat{y}_i}{\partial z_i} = \frac{\partial}{\partial z_i} \left( \frac{e^{z_i}}{\sum_j e^{z_j}} \right)$$

使用商法则：
$$= \frac{e^{z_i} \cdot \sum_j e^{z_j} - e^{z_i} \cdot e^{z_i}}{(\sum_j e^{z_j})^2}
= \frac{e^{z_i}}{\sum_j e^{z_j}} \cdot \left(1 - \frac{e^{z_i}}{\sum_j e^{z_j}}\right)
= \hat{y}_i (1 - \hat{y}_i)$$

**情况2：当 $k \neq i$ 时**
$$\frac{\partial \hat{y}_k}{\partial z_i} = \frac{\partial}{\partial z_i} \left( \frac{e^{z_k}}{\sum_j e^{z_j}} \right)
= \frac{0 \cdot \sum_j e^{z_j} - e^{z_k} \cdot e^{z_i}}{(\sum_j e^{z_j})^2}
= -\frac{e^{z_k}}{\sum_j e^{z_j}} \cdot \frac{e^{z_i}}{\sum_j e^{z_j}}
= -\hat{y}_k \hat{y}_i$$

**总结**：
$$\frac{\partial \hat{y}_k}{\partial z_i} = 
\begin{cases}
\hat{y}_i (1 - \hat{y}_i) & \text{if } k = i \\
-\hat{y}_k \hat{y}_i & \text{if } k \neq i
\end{cases}$$

更紧凑地，可以使用 Kronecker delta 函数表示：
$$\frac{\partial \hat{y}_k}{\partial z_i} = \hat{y}_k (\delta_{ki} - \hat{y}_i)$$
其中 $\delta_{ki} = 1$ 当 $k = i$，否则为 0。

## 3. 交叉熵损失的梯度推导

现在，我们推导 $\frac{\partial L}{\partial z_i}$：

$$L = -\sum_{j=1}^C y_j \log(\hat{y}_j)$$

$$\frac{\partial L}{\partial z_i} = -\sum_{j=1}^C y_j \frac{\partial \log(\hat{y}_j)}{\partial z_i}
= -\sum_{j=1}^C y_j \frac{1}{\hat{y}_j} \frac{\partial \hat{y}_j}{\partial z_i}$$

代入 softmax 的导数：
$$= -\sum_{j=1}^C y_j \frac{1}{\hat{y}_j} \cdot \hat{y}_j (\delta_{ji} - \hat{y}_i)
= -\sum_{j=1}^C y_j (\delta_{ji} - \hat{y}_i)$$

展开求和：
$$= -\left( \sum_{j=1}^C y_j \delta_{ji} - \sum_{j=1}^C y_j \hat{y}_i \right)
= -\left( y_i - \hat{y}_i \sum_{j=1}^C y_j \right)$$

由于 $y$ 是 one-hot 编码，$\sum_{j=1}^C y_j = 1$，所以：
$$\frac{\partial L}{\partial z_i} = -(y_i - \hat{y}_i) = \hat{y}_i - y_i$$

## 4. 向量形式

将上述结果写成向量形式：
$$\frac{\partial L}{\partial z} = 
\begin{bmatrix}
\frac{\partial L}{\partial z_1} \\
\frac{\partial L}{\partial z_2} \\
\vdots \\
\frac{\partial L}{\partial z_C}
\end{bmatrix}
= 
\begin{bmatrix}
\hat{y}_1 - y_1 \\
\hat{y}_2 - y_2 \\
\vdots \\
\hat{y}_C - y_C
\end{bmatrix}
= \hat{y} - y$$

</details>

<details><summary>这里是一种实现方式</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,datasets,Learning_rate=0.001):
        self.datasets = datasets
        self.X = self.datasets[['x','y']].values
        self.y = pd.get_dummies(self.datasets['label']).values
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []
        self.H1 = None
        self.H2 = None
        self.logits = None
        self.Learning_rate = Learning_rate

     def softmax(self):
        _ = np.exp(self.logits - np.max(self.logits, axis=1, keepdims=True))
        softmax_logits = _ / np.sum(_, axis=1, keepdims=True)
        return softmax_logits

    def relu(self, M):
        return np.maximum(0, M)

    def deriv_relu(self, M):
        return (M > 0).astype(float)
        
    def CE(self,M_pred,M_true):
        epsilon = 1e-10
        M_pred = np.clip(M_pred, epsilon, 1. - epsilon)
        M_CE = -M_true*np.log(M_pred)
        return M_CE

    def compute_loss(self):
        return np.mean(np.sum(self.CE(self.softmax(),self.y),axis=1))

    def forward(self):
        self.H1 = self.relu(self.X @self.W1 + self.b1)
        self.H2 = self.relu(self.H1 @self.W2 + self.b2)
        self.logits = self.H2 @self.W3 + self.b3
        self.loss.append(self.compute_loss())

    def backward(self):
        self.dL_dlogits = self.softmax() - self.y
        self.dL_dH2 = self.dL_dlogits @ self.W3.T * self.deriv_relu(self.H2)
        self.dL_dH1 = self.dL_dH2 @ self.W2.T * self.deriv_relu(self.H1)
        self.dL_dW3 = self.H2.T @ self.dL_dlogits
        self.dL_dW2 = self.H1.T @ self.dL_dH2
        self.dL_dW1 = self.X.T @ self.dL_dH1
        self.dL_db3 = np.sum(self.dL_dlogits, axis=1, keepdims=True)
        self.dL_db2 = np.sum(self.dL_dH2, axis=1, keepdims=True)
        self.dL_db1 = np.sum(self.dL_dH1, axis=1, keepdims=True)

        self.W3 -= self.Learning_rate * self.dL_dW3
        self.W2 -= self.Learning_rate * self.dL_dW2
        self.W1 -= self.Learning_rate * self.dL_dW1
        self.b3 -= self.Learning_rate * self.dL_db3
        self.b2 -= self.Learning_rate * self.dL_db2
        self.b1 -= self.Learning_rate * self.dL_db1

```

</details>


### 5.训练函数

我们开始定义训练函数fit（这个词有拟合的意思）。
这时，需要fit实现以下功能：
实现前向传递和反向传递。
依照batch_size将数据集分成不同的batch（批次），并将batch_size对学习率等变量的影响纳入考虑。
如果不考虑batch，那么是这样的：
```python
def fit(self):
        sample_count = len(self.X)
        for epoch in range(self.epochs):
            indices = np.arange(sample_count)
            np.random.shuffle(indices)
            X_shuffled = self.X[indices]
            y_shuffled = self.y[indices]
            self.X = X_shuffled
            self.y = y_shuffled
                self.forward()
                self.backward()
            if epoch % 100 == 0:
                print(f'Epoch {epoch}, Loss: {self.loss[-1]}')
```

我们打乱了样本的顺序，并再次为X，y赋值以增加随机性。（这主要是为了提升代码的可扩展性，由于我们的数据集本来就是随机生成的。当数据集不保证随机时，这样很有用。）
并且，我们每过100epoch会打印一次loss，使我们直观地看到训练效果。

如果考虑到batch，我们需要修改X和y的代码来适应————首先，我们要将X和y切成“一段一段”的批次。我们可以这样做：
```python
    def __init__(self,datasets,Learning_rate=0.01,batch_size=80,epochs=1000):
        self.datasets = datasets
        self.X_full = self.datasets[['x','y']].values
        self.y_full = pd.get_dummies(self.datasets['label']).values
        self.X = None
        self.y = None
        ...#剩下的是其他初始化定义，跳过

        ...#跳过其他函数
    def forward(self):
        self.H1 = self.relu(self.X @self.W1 + self.b1)
        self.H2 = self.relu(self.H1 @self.W2 + self.b2)
        self.logits = self.H2 @self.W3 + self.b3
        #删除forward中的计算损失，并单独放在fit中，以便计算批次平均损失

    def fit(self):
        sample_count = len(self.X_full)
        for epoch in range(self.epochs):
            indices = np.arange(sample_count)
            np.random.shuffle(indices)
            X_shuffled = self.X_full[indices]
            y_shuffled = self.y_full[indices]
            epoch_loss = []
            for start_idx in range(0, sample_count, self.batch_size):
                end_idx = min(start_idx + self.batch_size, sample_count)
                self.X = X_shuffled[start_idx:end_idx]
                self.y = y_shuffled[start_idx:end_idx]
                self.forward()
                epoch_loss.append(self.compute_loss())
                self.backward()
            self.loss.append(np.mean(epoch_loss))
            if epoch % 100 == 0:
                print(f'Epoch {epoch}, Loss: {self.loss[-1]}')


```
这样，我们就解决了分割问题。与此同时，我们将损失也进行了归一化，使得batch的多少不会影响损失。
那么，这是全部代码：
<details><summary>点这里展开</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,datasets,Learning_rate=0.01,batch_size=80,epochs=1000):
        self.datasets = datasets
        self.X_full = self.datasets[['x','y']].values
        self.y_full = pd.get_dummies(self.datasets['label']).values
        self.X = None
        self.y = None
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []
        self.H1 = None
        self.H2 = None
        self.logits = None
        self.Learning_rate = Learning_rate
        self.batch_size = batch_size
        self.epochs = epochs
    
    def softmax(self):
        _ = np.exp(self.logits - np.max(self.logits, axis=1, keepdims=True))
        softmax_logits = _ / np.sum(_, axis=1, keepdims=True)
        return softmax_logits

    def relu(self, M):
        return np.maximum(0, M)
    
    def deriv_relu(self, M):
        return (M > 0).astype(float)
    
    def CE(self,M_pred,M_true):
        epsilon = 1e-10
        M_pred = np.clip(M_pred, epsilon, 1. - epsilon)
        M_CE = -M_true*np.log(M_pred)
        return M_CE
    def compute_loss(self):
        return np.sum(np.mean(self.CE(self.softmax(),self.y),axis=1))
    
    def forward(self):
        self.H1 = self.relu(self.X @self.W1 + self.b1)
        self.H2 = self.relu(self.H1 @self.W2 + self.b2)
        self.logits = self.H2 @self.W3 + self.b3

    def backward(self):
        self.dL_dlogits = self.softmax() - self.y
        self.dL_dH2 = self.dL_dlogits @ self.W3.T * self.deriv_relu(self.H2)
        self.dL_dH1 = self.dL_dH2 @ self.W2.T * self.deriv_relu(self.H1)
        self.dL_dW3 = self.H2.T @ self.dL_dlogits
        self.dL_dW2 = self.H1.T @ self.dL_dH2
        self.dL_dW1 = self.X.T @ self.dL_dH1
        self.dL_db3 = np.sum(self.dL_dlogits, axis=0, keepdims=True)
        self.dL_db2 = np.sum(self.dL_dH2, axis=0, keepdims=True)
        self.dL_db1 = np.sum(self.dL_dH1, axis=0, keepdims=True)

        self.W3 -= self.Learning_rate * self.dL_dW3
        self.W2 -= self.Learning_rate * self.dL_dW2
        self.W1 -= self.Learning_rate * self.dL_dW1
        self.b3 -= self.Learning_rate * self.dL_db3
        self.b2 -= self.Learning_rate * self.dL_db2
        self.b1 -= self.Learning_rate * self.dL_db1

    def fit(self):
        sample_count = len(self.X_full)
        for epoch in range(self.epochs):
            indices = np.arange(sample_count)
            np.random.shuffle(indices)
            X_shuffled = self.X_full[indices]
            y_shuffled = self.y_full[indices]
            epoch_loss = []
            for start_idx in range(0, sample_count, self.batch_size):
                end_idx = min(start_idx + self.batch_size, sample_count)
                self.X = X_shuffled[start_idx:end_idx]
                self.y = y_shuffled[start_idx:end_idx]
                self.forward()
                epoch_loss.append(self.compute_loss())
                self.backward()
            self.loss.append(np.mean(epoch_loss))
            if epoch % 100 == 99:
                print(f'Epoch {epoch+1}, Loss: {self.loss[-1]}')

```

</details>

### 6.推理函数
胜利在望！到目前位置你已经完成了大半。我们构造好了全部的训练代码，最后就是推理和实践了。
我们要写出一个predict函数，给出验证集x，y，要输出它的预测值（0或1，代表在区域内还是区域外）。为了实现这一点，我们不再输入数据集，而是输入训练集和验证集。
<details><summary>以下是修改的地方</summary>

```python
    def __init__(self,train_set,val_set,Learning_rate=0.01,batch_size=80,epochs=1000):
            self.train_set = train_set
            self.val_set = val_set
            self.X_full = self.train_set[['x','y']].values
            self.y_full = pd.get_dummies(self.train_set['label']).values
            ... #余下初始化不变

    #省略其他函数

    def predict(self, X):
            self.X = self.val_set[['x','y']].values
            self.forward()
            return np.argmax(self.softmax(), axis=1)
```

</details>


<details><summary>以下是全部代码</summary>

```python
import numpy as np
import pandas as pd

class MLPClassifier:
    def __init__(self,train_set,val_set,Learning_rate=0.01,batch_size=80,epochs=1000):
        self.train_set = train_set
        self.val_set = val_set
        self.X_full = self.train_set[['x','y']].values
        self.y_full = pd.get_dummies(self.train_set['label']).values
        self.X = None
        self.y = None
        self.W1 = np.random.randn(2, 4) * np.sqrt(2. / 4) # He初始化
        self.b1 = np.zeros((1, 4))
        self.W2 = np.random.randn(4, 4) * np.sqrt(2. / 4)
        self.b2 = np.zeros((1, 4))
        self.W3 = np.random.randn(4, 2) * np.sqrt(2. / 2)
        self.b3 = np.zeros((1, 2))
        self.loss = []
        self.H1 = None
        self.H2 = None
        self.logits = None
        self.Learning_rate = Learning_rate
        self.batch_size = batch_size
        self.epochs = epochs
    
    def softmax(self):
        _ = np.exp(self.logits - np.max(self.logits, axis=1, keepdims=True))
        softmax_logits = _ / np.sum(_, axis=1, keepdims=True)
        return softmax_logits

    def relu(self, M):
        return np.maximum(0, M)
    
    def deriv_relu(self, M):
        return (M > 0).astype(float)
    
    def CE(self,M_pred,M_true):
        epsilon = 1e-10
        M_pred = np.clip(M_pred, epsilon, 1. - epsilon)
        M_CE = -M_true*np.log(M_pred)
        return M_CE
    def compute_loss(self):
        return np.sum(np.mean(self.CE(self.softmax(),self.y),axis=1))
    
    def forward(self):
        self.H1 = self.relu(self.X @self.W1 + self.b1)
        self.H2 = self.relu(self.H1 @self.W2 + self.b2)
        self.logits = self.H2 @self.W3 + self.b3

    def backward(self):
        self.dL_dlogits = self.softmax() - self.y
        self.dL_dH2 = self.dL_dlogits @ self.W3.T * self.deriv_relu(self.H2)
        self.dL_dH1 = self.dL_dH2 @ self.W2.T * self.deriv_relu(self.H1)
        self.dL_dW3 = self.H2.T @ self.dL_dlogits
        self.dL_dW2 = self.H1.T @ self.dL_dH2
        self.dL_dW1 = self.X.T @ self.dL_dH1
        self.dL_db3 = np.sum(self.dL_dlogits, axis=0, keepdims=True)
        self.dL_db2 = np.sum(self.dL_dH2, axis=0, keepdims=True)
        self.dL_db1 = np.sum(self.dL_dH1, axis=0, keepdims=True)

        self.W3 -= self.Learning_rate * self.dL_dW3
        self.W2 -= self.Learning_rate * self.dL_dW2
        self.W1 -= self.Learning_rate * self.dL_dW1
        self.b3 -= self.Learning_rate * self.dL_db3
        self.b2 -= self.Learning_rate * self.dL_db2
        self.b1 -= self.Learning_rate * self.dL_db1

    def fit(self):
        sample_count = len(self.X_full)
        for epoch in range(self.epochs):
            indices = np.arange(sample_count)
            np.random.shuffle(indices)
            X_shuffled = self.X_full[indices]
            y_shuffled = self.y_full[indices]
            epoch_loss = []
            for start_idx in range(0, sample_count, self.batch_size):
                end_idx = min(start_idx + self.batch_size, sample_count)
                self.X = X_shuffled[start_idx:end_idx]
                self.y = y_shuffled[start_idx:end_idx]
                self.forward()
                epoch_loss.append(self.compute_loss())
                self.backward()
            self.loss.append(np.mean(epoch_loss))
            if epoch % 100 == 99:
                print(f'Epoch {epoch+1}, Loss: {self.loss[-1]}')

    def predict(self, X):
        self.X = self.val_set[['x','y']].values
        self.forward()
        return np.argmax(self.softmax(), axis=1)
```

</details>
至此，我们实现了MLPClassifier这个类！

## 二.在主函数中调用类，完成训练吧！

让我们将以上的文件打包成Model.py,放在mission1文件夹中。

#### 在真正训练前，我们还要创建数据集的准备。
你可以直接用我创建csv的函数：

[注：pandas入门](https://www.zhihu.com/question/484589541/answer/1948702631515096189)

<details><summary>点击展开（data_creater.py）</summary>

```python
import numpy as np
import pandas as pd

def create_data(n=1000, variance=6.0,
                 out_path="data.csv", seed=42,
                 condition="((x**2 + y**2) <= 1.0**2)"):
    np.random.seed(seed)
    # 独立的两个正态分布：均值0，方差variance（协方差为0）
    samples = np.random.normal(loc=0.0, scale=np.sqrt(variance), size=(n, 2))
    x = samples[:, 0]
    y = samples[:, 1]
    labels = (eval(condition)).astype(int)
    df = pd.DataFrame({"x": x, "y": y, "label": labels})
    df.to_csv(out_path, index=False)
```

</details>

这个函数会生成1000行3列的原始数据，3列分别表示x，y，是否在区域内。
目前的设定是，x和y服从方差为均为6，协方差为0的正态分布。当点在位于中心，半径为1的圆内时标签判定为1。你可以自行修改condition来改变条件。

这个代码被命名为data_creater,存储在mission_1文件夹下。

### 下面我们来正式实现主函数（mission_1.py）。
我们要在主函数中利用之前创造的类和数据生成函数，实现：
1.生成并分割数据。（或是直接生成两份训练和验证数据）
2.用训练集训练模型。
3.用验证集验证模型，并实现可视化。
下面分步骤列出了代码编写过程，以供参考：

#### 1.数据准备

<details><summary>以下是参考代码</summary>

```python
import numpy as np  # 数据处理
import pandas as pd # 数据处理
from data_creater import create_data

create_data(n=800,out_path='train_data.csv')  # 生成数据文件
create_data(n=200,out_path='val_data.csv')
train_df = pd.read_csv('train_data.csv')
val_df = pd.read_csv('val_data.csv')
```
我采用的是创建两份数据集，分别作为训练和验证集的方法。你也可以先创造一份再分割。

</details>

#### 2.训练模型

<details><summary>以下是参考代码</summary>

```python
import numpy as np  # 数据处理
import pandas as pd # 数据处理
from data_creater import create_data
from Model import MLPClassifier

create_data(n=800,out_path='train_data.csv')  # 生成数据文件
create_data(n=200,out_path='val_data.csv')
train_df = pd.read_csv('train_data.csv')
val_df = pd.read_csv('val_data.csv')
model = MLPClassifier(train_set=train_df, val_set=val_df,
                      Learning_rate=0.01, batch_size=80, epochs=1000)
model.fit()
```

在这个阶段，我们简单地调用了之前写的Model代码，这也体现了封装的重要性。

</details>

#### 3.模型推理与可视化

<details><summary>以下是参考代码</summary>

```python
import numpy as np  # 数据处理
import pandas as pd # 数据处理
import seaborn as sns # 画图
from data_creater import create_data
from Model import MLPClassifier

create_data(n=800,out_path='train_data.csv')  # 生成数据文件
create_data(n=200,out_path='val_data.csv')
train_df = pd.read_csv('train_data.csv')
val_df = pd.read_csv('val_data.csv')
model = MLPClassifier(train_set=train_df, val_set=val_df,
                      Learning_rate=0.01, batch_size=80, epochs=1000)
model.fit()
prediction = model.predict()
sns.scatterplot(x=val_df['x'], y=val_df['y'], hue=prediction,data=val_df) # 预测结果可视化
plt.show()
```

[注：seaborn是什么？](https://zhuanlan.zhihu.com/p/49035741)

</details>

####

接下来，不出意外的话，你通过命令行运行mission_1.py：

```bash

cd (你的目录)
python mission_1.py

```

之后就可以看到每100个epoch对应的损失率，在结束之后还能看到模型对验证集的推理情况，实验完成！

值得一提的是，这个模型的鲁棒性十分脆弱。你可以试试改一些激活函数和参数，会发现模型轻易就会崩掉（如损失陡增，数值溢出...）在接下来的实验中，我们将了解模型“崩掉”的成因，优化代码，增强代码的规范性、拓展性与鲁棒性。

### 在下个试验等你

![alt text](picture/illustration_mission_1.png)